{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification\n",
    "#### Identify and classify toxic online comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Goal](#goal)  \n",
    "2. [Data](#dat) \n",
    "4. [Load Data](#loaddata)    \n",
    "5. [Feature Extraction](#features)    \n",
    "6. [Naïve Bayes](#nb)  \n",
    "7. [Stochastic Gradient Descent](#sgd) \n",
    "8. [Results](#result) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='goal'></a>\n",
    "## Goal  \n",
    "Study negative online behaviors, like toxic comments (comments that are rude, disrespectful or otherwise likely \n",
    "to make someone leave a discussion) and build a model to identify type of toxicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dat'></a>\n",
    "## Data  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is taken from kaggle Toxic Comment Classification Challenge.\n",
    "\n",
    "URL: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline,FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loaddata'></a>\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('D:/Kaggle/Toxic Comment Classification Challenge/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('D:/Kaggle/Toxic Comment Classification Challenge/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='features'></a>\n",
    "## Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_count_vect=CountVectorizer(ngram_range=(1,2),min_df=3,strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='nb'></a>\n",
    "## Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_NB = MultinomialNB()\n",
    "pipe = Pipeline([(\"word_count_vect\", word_count_vect),('NB',clf_NB)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for label toxic.......\n",
      "AUC for lable toxic 0.91684\n",
      "Testing for label toxic.......\n",
      "Prediction ready for label toxic.......\n",
      "#####################################################\n",
      "Training for label severe_toxic.......\n",
      "AUC for lable severe_toxic 0.90191\n",
      "Testing for label severe_toxic.......\n",
      "Prediction ready for label severe_toxic.......\n",
      "#####################################################\n",
      "Training for label obscene.......\n",
      "AUC for lable obscene 0.91227\n",
      "Testing for label obscene.......\n",
      "Prediction ready for label obscene.......\n",
      "#####################################################\n",
      "Training for label threat.......\n",
      "AUC for lable threat 0.78705\n",
      "Testing for label threat.......\n",
      "Prediction ready for label threat.......\n",
      "#####################################################\n",
      "Training for label insult.......\n",
      "AUC for lable insult 0.909\n",
      "Testing for label insult.......\n",
      "Prediction ready for label insult.......\n",
      "#####################################################\n",
      "Training for label identity_hate.......\n",
      "AUC for lable identity_hate 0.80486\n",
      "Testing for label identity_hate.......\n",
      "Prediction ready for label identity_hate.......\n",
      "#####################################################\n",
      "Avg AUC  0.872\n"
     ]
    }
   ],
   "source": [
    "target=['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "Total_Auc=0\n",
    "\n",
    "for i in target:\n",
    "    print('Training for label '+str(i)+'.......')\n",
    "    cv_score = np.mean(cross_val_score(pipe, train['comment_text'].values, train[i].values, cv=3, scoring='roc_auc'))\n",
    "    Total_Auc=Total_Auc+cv_score\n",
    "    print('AUC for lable '+str(i)+' '+str(round(cv_score,5)))\n",
    "    pipe.fit(train['comment_text'].values, train[i].values)\n",
    "    print('Testing for label '+str(i)+'.......')\n",
    "    test[i]=pipe.predict_proba(test['comment_text'].values)[:, 1]\n",
    "    print('Prediction ready for label '+str(i)+'.......')\n",
    "    print('#####################################################')\n",
    "print('Avg AUC ',round(float(Total_Auc/6),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.loc[:,['id','toxic','severe_toxic','obscene','threat','insult','identity_hate']].to_csv('ToxicComments_Submission_NB.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sgd'></a>\n",
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SGD=SGDClassifier(n_iter=100,random_state=100,loss='log')\n",
    "pipe = Pipeline([(\"word_count_vect\", word_count_vect),('SGD',SGD)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', n_iter=100, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=100, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for label toxic.......\n",
      "AUC for lable toxic 0.95732\n",
      "Testing for label toxic.......\n",
      "Prediction ready for label toxic.......\n",
      "#####################################################\n",
      "Training for label severe_toxic.......\n",
      "AUC for lable severe_toxic 0.96394\n",
      "Testing for label severe_toxic.......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Snehal Gawas\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:352: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction ready for label severe_toxic.......\n",
      "#####################################################\n",
      "Training for label obscene.......\n",
      "AUC for lable obscene 0.97131\n",
      "Testing for label obscene.......\n",
      "Prediction ready for label obscene.......\n",
      "#####################################################\n",
      "Training for label threat.......\n",
      "AUC for lable threat 0.94577\n",
      "Testing for label threat.......\n",
      "Prediction ready for label threat.......\n",
      "#####################################################\n",
      "Training for label insult.......\n",
      "AUC for lable insult 0.95935\n",
      "Testing for label insult.......\n",
      "Prediction ready for label insult.......\n",
      "#####################################################\n",
      "Training for label identity_hate.......\n",
      "AUC for lable identity_hate 0.93743\n",
      "Testing for label identity_hate.......\n",
      "Prediction ready for label identity_hate.......\n",
      "#####################################################\n",
      "Avg AUC  0.956\n"
     ]
    }
   ],
   "source": [
    "target=['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "Total_Auc=0\n",
    "\n",
    "for i in target:\n",
    "    print('Training for label '+str(i)+'.......')\n",
    "    cv_score = np.mean(cross_val_score(pipe, train['comment_text'].values, train[i].values, cv=3, scoring='roc_auc'))\n",
    "    Total_Auc=Total_Auc+cv_score\n",
    "    print('AUC for lable '+str(i)+' '+str(round(cv_score,5)))\n",
    "    pipe.fit(train['comment_text'].values, train[i].values)\n",
    "    print('Testing for label '+str(i)+'.......')\n",
    "    test[i]=pipe.predict_proba(test['comment_text'].values)[:, 1]\n",
    "    print('Prediction ready for label '+str(i)+'.......')\n",
    "    print('#####################################################')\n",
    "print('Avg AUC ',round(float(Total_Auc/6),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.loc[:,['id','toxic','severe_toxic','obscene','threat','insult','identity_hate']].to_csv('ToxicComments_Submission_SGD.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='result'></a>\n",
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naïve Bayes**\n",
    "- Cross Validation Score = 0.872\n",
    "- Test Data Score (kaggle Private score) = 0.865\n",
    "\n",
    "**Stochastic Gradient Descent**\n",
    "- Cross Validation Score = 0.956\n",
    "- Test Data Score = 0.954"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
